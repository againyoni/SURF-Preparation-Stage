# -*- coding: utf-8 -*-
"""Image Classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18teVtDWFX2fWQyuzeXGFANuJJq5Sr1An

# Image Classification using CNN
In this report, it will evaluate the image classification, typically CIFAR-10 having 10 classes.

The development is proceeded with "tensorflow, keras, matplotlib, numpy, sklearn and metric" technologies. The images will be classified in two different method: Artificial Neural Network and Convolutional Neural Network. Then, the results will be compared and see better networking for classification. Lastly, the prediction will be made.
"""

import tensorflow as tf
from keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np

(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()
X_train.shape

X_test.shape

y_train.shape

X_train[0] # 32X32

y_train = y_train.reshape(-1,) # second dimension == flatten == blank
y_train[:5] # now one dimensional array printed

"""For the shape of training, two dimensional array is not needed. Opposingly, categorizing is needed. Therefore, y_train can be reshaped."""

y_test = y_test.reshape(-1,)

"""With reshaped train and test to be in one-dimensional array, the classes are then can be evaluated."""

classes = ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]

"""It defines the 10 classes, where the pictures need to be classified.

Then the classes can be printed by classes[index].
Therefore the x_label classes can be re written as plt.xlabel(classes[y[index]]).
"""

def plot_sample(X, y, index): # to print out the picture that I want only
    plt.figure(figsize = (15, 2))
    plt.imshow(X[index])
    plt.xlabel(classes[y[index]]) # print out the x label --> i.g. whether it is frog / train = classes
    # but how to use the classes? --> need to define y

"""plt.imshow(X_train[n]):
It will print out the picture that needs classification.
This is printed in 32X32 pixels.

It also prints out the size of the image.
"""

plot_sample(X_train, y_train, 0)

plot_sample(X_train, y_train, 3)

"""# Artificial Neural Network"""

# apply to all the image inputs
X_train = X_train / 255
X_test = X_test / 255

"""Now the data is needed to be normalized. This is required to ensure how the data is look like, the data reads and utilization by the recorded database.

To normalize in ANN, images are divided by each pixel value, 255. This represents the RGB maximum value.
"""

ann = models.Sequential([
        layers.Flatten(input_shape = (32, 32, 3)), # first layer which accepts 32X32X3
        layers.Dense(3000, activation = 'relu'), # having 3000 neurons
        layers.Dense(1000, activation = 'relu'), # 1000 neurons
        layers.Dense(10, activation = 'sigmoid') # then 10 categories
])

# dense artificial neural network with the following parameters
ann.compile(optimizer = 'SGD',
                loss = 'sparse_categorical_crossentropy',
                metrics = ['accuracy'])

ann.fit(X_train, y_train, epochs = 5) # accuracy == low for training
# artifical neural network performs bad with 5 epochs

"""Notice on the performance of the Artificial Neural Network.

The parameter of loos in compilation function can be inputted with two distinct entropies, "categorical crossentropy" and "sparse categorical crossentropy".
The difference between them is that categorical crossentropy uses matrix to retrieve the image, where sparsed one uses a value.

Therefore, since the above codes used values to get the class and image, it uses "spare categorical crossentropy" for loss parameter.
"""

ann.evaluate(X_test, y_test)

"""The test case matrices and 1-dimension of size 10 is evaluated for total accuracy."""

from sklearn.metrics import confusion_matrix, classification_report
import numpy as np
y_pred = ann.predict(X_test)
y_pred_classes = [np.argmax(element) for element in y_pred]

print("Classification Report: \n", classification_report(y_test, y_pred_classes, zero_division='warn'))

"""The above result is a classificantion report which can look at the accuracy percentage for each classes.

# Convolutional Neural Network
"""

cnn = models.Sequential([
        # cnn
        layers.Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', input_shape = [32, 32, 3]), # 3X3 kernel, 32 filters
        layers.MaxPooling2D((2, 2)), # less expensive to calculate

        layers.Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'), 
        layers.MaxPooling2D((2, 2)),

        # dense network
        layers.Flatten(), # first layer which accepts 32X32X3
        layers.Dense(64, activation = 'relu'), # keep only one layer
        layers.Dense(10, activation = 'softmax') # normalize probability
]) # up-pooling

"""Convolution layers:

1. first one detects the loopy pattern
2. detecting the vertical line
3. detecting the diagonal line

Best thing about the cnn:
don't need to tell what the filters are.
It will figure out filter by itself, which filter size and how many filters are needed can be calculated by the convolution function itself.
"""

cnn.compile(optimizer = 'adam',
              loss = 'sparse_categorical_crossentropy',
              metrics = ['accuracy'])

cnn.fit(X_train, y_train, epochs = 10)

"""By the comparison from the above evaluated accuracies for ANN and CNN accuracies just computed, it is noticeable that CNN has higher accuracy for image classification.

In convolution layer, the normalization works little different from ANN. As it is mentioned in the above, ANN convolution layer is a simple division with RGB value. However, in CNN, the normalization is the addition of the neighboring epoch's accuracy and dividing from the targetting accuracy value from the added value. This will give the CNN normalization.
"""

cnn.evaluate(X_test, y_test)

y_test = y_test.reshape(-1,)
plot_sample(X_test, y_test, 4)

y_pred = cnn.predict(X_test)
y_pred[:5]

"""The values in the array is probability distribution between 0 and 1.
To get the prediction value, find which element is max. This can be done by the use of argmax method.
"""

y_classes = [np.argmax(element) for element in y_pred] # the number displayed is the maximum element
y_classes[:5] # prediction

y_test[:5] # expectation

"""Although the predictions make some errors, results are almost the same and some are even difficult to recognize by human. Thus, the outcome is still reasonable with such errors."""

classes[y_classes[4]] # this is the actual value with input of 4 = 'frog' 
# the output = predicted value, it matches the expectation